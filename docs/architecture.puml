@startuml Reconable Lite+ Architecture

!theme plain
skinparam backgroundColor #FFFFFF
skinparam componentStyle rectangle
skinparam packageStyle rectangle

title Reconable Lite+ - Multi-Agent LinkedIn Analysis Platform

package "Frontend Layer" {
  [Dashboard UI] as UI
  [Real-time Monitoring] as Monitor
  [Analysis Reports] as Reports
}

package "Cloudflare Workers" {
  [Main Worker] as Worker
  [API Routes] as API
  [Static Assets] as Assets
}

package "Durable Objects" {
  [Subject Orchestrator] as Orchestrator
  [State Machine] as StateMachine
}

package "AI Agents" {
  [Harvester Agent] as Harvester
  [Compliance Agent] as Compliance
  [Workers AI] as WorkersAI
}

package "Memory Systems" {
  [D1 Database] as D1
  [Vectorize Index] as Vectorize
  [Canonical Facts] as Canonical
  [Semantic Embeddings] as Embeddings
}

package "External Services" {
  [Brightdata API] as Brightdata
  [LinkedIn Profiles API] as LinkedInAPI
  [Web Scraping] as Scraping
}

package "Data Flow" {
  [Evidence Collection] as Evidence
  [Claim Extraction] as Claims
  [Verification] as Verify
  [Synthesis] as Synthesis
}

' Frontend connections
UI --> Worker : HTTPS
Monitor --> Worker : WebSocket
Reports --> Worker : API Calls

' Worker connections
Worker --> API : Route Requests
Worker --> Assets : Serve Static Files
Worker --> Orchestrator : Create/Manage Runs

' Orchestrator connections
Orchestrator --> StateMachine : Execute Pipeline
StateMachine --> Harvester : Harvest Evidence
StateMachine --> Compliance : Verify Claims
StateMachine --> WorkersAI : Generate Synthesis

' Agent connections
Harvester --> Brightdata : Scrape LinkedIn
Harvester --> Evidence : Collect Data
Compliance --> Verify : Check Privacy
WorkersAI --> Synthesis : Generate Reports

' Memory connections
Evidence --> D1 : Store Raw Data
Evidence --> Vectorize : Generate Embeddings
Claims --> D1 : Store Facts
Claims --> Vectorize : Store Embeddings
Synthesis --> D1 : Store Results

' External service connections
Brightdata --> LinkedInAPI : Profile Data
Brightdata --> Scraping : Web Content

' Data flow connections
Evidence --> Claims : Extract Facts
Claims --> Verify : Check Compliance
Verify --> Synthesis : Generate Report

' Styling
UI #E3F2FD
Worker #FFF3E0
Orchestrator #F3E5F5
Harvester #E8F5E8
Compliance #FFF8E1
WorkersAI #E0F2F1
D1 #FCE4EC
Vectorize #F1F8E9
Brightdata #E8EAF6

note right of Orchestrator
  **State Machine Pipeline:**
  1. INTAKE → DISCOVER
  2. DISCOVER → FETCH
  3. FETCH → NORMALIZE
  4. NORMALIZE → EXTRACT
  5. EXTRACT → VERIFY
  6. VERIFY → UPSERT
  7. UPSERT → SYNTHESIZE
  8. SYNTHESIZE → PUBLISH
end note

note right of Harvester
  **Data Sources:**
  • LinkedIn Profile URLs
  • Natural Language Search
  • Company Information
  • Web Content
end note

note right of Compliance
  **Privacy Controls:**
  • Consent Verification
  • PII Redaction
  • Policy Tagging
  • Data Governance
end note

note right of WorkersAI
  **AI Capabilities:**
  • Information Extraction
  • Claim Verification
  • Report Synthesis
  • Profile Analysis
end note

note bottom of D1
  **Canonical Storage:**
  • Evidence (raw data)
  • Claims (extracted facts)
  • Subject Runs (metadata)
  • Synthesis Results
end note

note bottom of Vectorize
  **Semantic Search:**
  • 768-dimension embeddings
  • Cosine similarity
  • Evidence retrieval
  • Claim matching
end note

@enduml